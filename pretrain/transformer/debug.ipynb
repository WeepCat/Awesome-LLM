{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-22T13:58:10.504183Z",
     "start_time": "2024-12-22T13:58:10.501061Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from typing import Optional, List"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:58:10.718228Z",
     "start_time": "2024-12-22T13:58:10.715194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model: int, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, d_model)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.emb(x)"
   ],
   "id": "140dabb77a8bd4b3",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:58:10.874033Z",
     "start_time": "2024-12-22T13:58:10.867513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_sinusoidal_positional_encoding(d_model: int, max_len: int = 4096):\n",
    "    # Empty encodings vectors\n",
    "    encodings = torch.zeros(max_len, d_model)\n",
    "    # Position indexes\n",
    "    position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "    # $2 * i$\n",
    "    two_i = torch.arange(0, d_model, 2, dtype=torch.float32)\n",
    "    # $10000^{\\frac{2i}{d_{model}}}$\n",
    "    div_term = torch.exp(two_i * -(math.log(10000.0) / d_model))\n",
    "    # $PE_{p,2i} = sin\\Bigg(\\frac{p}{10000^{\\frac{2i}{d_{model}}}}\\Bigg)$\n",
    "    encodings[:, 0::2] = torch.sin(position * div_term)\n",
    "    # $PE_{p,2i + 1} = cos\\Bigg(\\frac{p}{10000^{\\frac{2i}{d_{model}}}}\\Bigg)$\n",
    "    encodings[:, 1::2] = torch.cos(position * div_term)\n",
    "    # Add batch dimension\n",
    "    encodings = encodings.unsqueeze(1).requires_grad_(False)\n",
    "    return encodings\n",
    "\n",
    "\n",
    "class SinusoidalPositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout_prob: float, max_len: int = 4096):\n",
    "        super().__init__()\n",
    "        self.register_buffer('positional_encoding', get_sinusoidal_positional_encoding(d_model, max_len), False)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        pe = self.positional_encoding[:x.shape[0]].detach().requires_grad_(False)\n",
    "        return self.dropout(x + pe)\n",
    "\n",
    "\n",
    "class LearnedPositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout_prob: float, max_len: int = 4096):\n",
    "        super().__init__()\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(max_len, 1, d_model), requires_grad=True)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        pe = self.positional_encoding[:x.shape[0]]\n",
    "        return self.dropout(x + pe)"
   ],
   "id": "ee354f6f13799b9e",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:58:11.017704Z",
     "start_time": "2024-12-22T13:58:11.007436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PrepareForMultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    approx a linear transformation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model: int, heads: int, d_k: int, bias: bool):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(d_model, heads * d_k, bias=bias)\n",
    "        self.heads = heads\n",
    "        self.d_k = d_k\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        head_shape = x.shape[:-1]\n",
    "        x = self.linear(x)\n",
    "        x = x.view(*head_shape, self.heads, self.d_k) # batch, length, heads, d_k\n",
    "        return x\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, heads: int, dropout_prob: float = 0.1, bias: bool = True,\n",
    "                 use_drop_key: bool = False, mask_ratio: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.d_k = d_model // heads\n",
    "        self.heads = heads\n",
    "        self.query = PrepareForMultiHeadAttention(d_model, heads, self.d_k, bias)\n",
    "        self.key = PrepareForMultiHeadAttention(d_model, heads, self.d_k, bias)\n",
    "        self.value = PrepareForMultiHeadAttention(d_model, heads, self.d_k, bias)\n",
    "        self.scale = 1 / math.sqrt(self.d_k)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.output = nn.Linear(d_model, d_model)\n",
    "        self.attn = None\n",
    "        self.use_drop_key = use_drop_key\n",
    "        self.mask_ratio = mask_ratio\n",
    "\n",
    "    def get_score(self, query: torch.Tensor, key: torch.Tensor):\n",
    "        score = torch.matmul(query, key.transpose(-2, -1))\n",
    "        return score\n",
    "\n",
    "    def prepare_mask(self, mask: torch.Tensor, query_shape: List[int], key_shape: List[int]):\n",
    "        assert len(mask.shape) == 2 or len(mask.shape) == 3\n",
    "        if mask.shape == 2:\n",
    "            assert mask.shape[0] == query_shape[1]\n",
    "            assert mask.shape[1] == key_shape[1]\n",
    "            mask = mask.unsqueeze(0)\n",
    "        else:\n",
    "            assert mask.shape[0] == 1 or mask.shape[0] == query_shape[0]\n",
    "            assert mask.shape[1] == query_shape[1]\n",
    "            assert mask.shape[2] == key_shape[1]\n",
    "        return mask\n",
    "\n",
    "    def forward(self, *,\n",
    "                query: torch.Tensor,\n",
    "                key: torch.Tensor,\n",
    "                value: torch.Tensor,\n",
    "                mask: Optional[torch.Tensor] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query: shape (batch_size, seq_len, d_model)\n",
    "            key: shape (batch_size, seq_len, d_model)\n",
    "            value: shape (batch_size, seq_len, d_model)\n",
    "            mask: shape (batch_size, seq_len, seq_len). Since we assume all data use a same mask, so\n",
    "                  here the shape also equals to (1, seq_len, seq_len)\n",
    "\n",
    "        Return:\n",
    "            out: shape (batch_size, seq_len, d_model). The output of a multihead attention layer\n",
    "        \"\"\"\n",
    "        seq_len, batch_size, _ = query.shape\n",
    "        if mask is not None:\n",
    "            mask = self.prepare_mask(mask, query.shape, key.shape)\n",
    "\n",
    "        query = self.query(query)\n",
    "        key = self.key(key)\n",
    "        value = self.value(value)\n",
    "\n",
    "        scores = self.get_score(query, key)\n",
    "        scores *= self.scale\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attn = self.softmax(scores)\n",
    "        x = torch.matmul(attn, value)\n",
    "        self.attn = attn.detach()\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, seq_len, -1)\n",
    "        return self.output(x)"
   ],
   "id": "f4a8f1b198ea576d",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:58:11.184019Z",
     "start_time": "2024-12-22T13:58:11.181531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = torch.tensor([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8]\n",
    "])"
   ],
   "id": "c6d24a62efe52742",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:58:12.025999Z",
     "start_time": "2024-12-22T13:58:11.920341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_embed = TokenEmbedding(d_model=512, vocab_size=32000)\n",
    "x = token_embed(inputs)"
   ],
   "id": "686a5e41b2f8419c",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:58:18.785451Z",
     "start_time": "2024-12-22T13:58:18.777285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pe = SinusoidalPositionalEncoding(d_model=512, dropout_prob=0.1, max_len=4096)\n",
    "x = pe(x)"
   ],
   "id": "10c7df2a19efd3f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:59:35.722059Z",
     "start_time": "2024-12-22T13:59:35.708443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mha = MultiHeadAttention(d_model=512, heads=8)\n",
    "mha(query=x, key=x, value=x)"
   ],
   "id": "64b0954b020cd40d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2bcc3a6a740ce030"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
