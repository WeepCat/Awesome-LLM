trainer_configs = {
    "learning_rate": 5e-6,
    "weight_decay": 0.,
    "num_train_epochs": 1,
    "val_strategy": "steps",
    "eval_every_steps": 10,
    "save_strategy": "steps",
    "save_every_steps": 999999,
    "gradient_accumulation_steps": 16,
    "gradient_checkpointing": True,
    "remove_unused_columns": False,
    "label_names": [],
    "deepspeed": None,
    "bf16": True,
    "optim": "adamw_torch",
    "lr_scheduler_type": "linear",
    "local_rank": -1,
    "logging_strategy": "steps",
    "logging_steps": 1,
    "use_flash_attention_2": False,
    "report_to": "wandb",
    "batch_eval_metrics": True,
    "auto_find_batch_size": True
}
